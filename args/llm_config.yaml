# LLM Configuration
# Simplified: Claude Opus 4.6 handles orchestration, synthesis, and reasoning.
# External LLMs only used when they provide unique value (data sources Claude can't access).

models:
  grok:
    provider: xai
    model: grok-3
    temperature: 0.8
    description: "X/social sentiment — unique data source Claude can't access directly"
    usage: optional  # Only when user wants social sentiment

# Retired models (Opus 4.6 makes these redundant):
# - codex (GPT-4o): Code gen/review — Claude does this natively
# - gemini (Gemini 2.0 Flash): Synthesis/reasoning — Claude does this better with full context
# - qwen (local MLX): Drafts/formatting — unnecessary overhead on laptop

# Architecture:
# Claude Opus 4.6 = orchestrator + synthesizer + reasoner
# Grok = optional social sentiment (unique X data)
# Alpaca MCP = live market data
# tools/data/*.py = deterministic calculations (TA indicators, data aggregation)

# Retry settings
retry:
  max_attempts: 3
  backoff_seconds: 2

# Timeout in seconds
timeout: 120
